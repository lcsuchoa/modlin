# ************************************************************************* #
#                                Aula Pr?tica 6                             #
# ************************************************************************* #

# ************************************************************************* #
# Exemplo pontos de influ?ncia: Exemplo 14.1                                #
# Material14_Modelos_2021_1                                                 #
# ************************************************************************* #

# Exemplo: tempo vs quantidade de bebida e distancia

y  = c(16.68,11.50,12.03,14.88,13.75,18.11,8.00,17.83,79.24,21.50,40.33,21.00,13.50,19.75,24.00,29.00,15.35,19.00,9.50,35.10,17.90,52.32,18.75,19.83,10.75)
x1 = c(7,3,3,4,6,7,2,7,30,5,16,10,4,6,9,10,6,7,3,17,10,26,9,8,4)
x2 = c(560,220,340,80,150,330,110,210,1460,605,688,215,255,462,448,776,200,132,36,770,140,810,450,635,150)

dados = data.frame(y,x1,x2)
plot(dados)

### Ajuste
ajuste = lm(y~x1+x2)
summary(ajuste)

### Gr?ficos dos res?duos
par(mfrow=c(1,2))
plot(fitted.values(ajuste),residuals(ajuste),xlab = 'Valores ajustedos' , ylab='Res?duos')
qqnorm(residuals(ajuste))
qqline(residuals(ajuste))

### Gr?ficos dos res?duos estudentizados
par(mfrow=c(1,2))
plot(fitted.values(ajuste),rstudent(ajuste),xlab = 'Valores ajustedos' , ylab='Res?duos')
qqnorm(rstudent(ajuste))
qqline(rstudent(ajuste))

# H? ind?cios de n?o normalidade e presen?a de outliers.

### Gr?ficos dos res?duos parciais
res.parc1=residuals(ajuste)+1.615907*x1
res.parc2=residuals(ajuste)+0.014385*x2
par(mfrow=c(1,2),cex=1.12)
plot(x1,res.parc1,xlab='x1',ylab='Res?duos parciais',pch=20)
plot(x2,res.parc2,xlab='x2',ylab='Res?duos parciais',pch=20)

#Os gr?ficos de res?duos parciais evidenciam a rela??o linear entre a vari?vel resposta Y e cada
#uma das vari?veis explicativas, X1 e X2. Indicam tamb?m a presen?a de valores discrepantes.

### C?lculo das medidas de influ?ncia
infmed=influence.measures(ajuste)
infmed
summary(infmed)

#As observa??es 9 e 22 requerem aten??o, pois h? ind?cios de que ambas sejam influentes,
#segundo as medidas de diagn?stico consideradas.


### Gr?ficos para detectar influ?ncia
# DFBETAS
par(mfrow=c(1,3),cex=1)
plot(infmed$infmat[,1], ylab="DFBeta(0)", pch=20)
plot(infmed$infmat[,2], ylab="DFBeta(1)", pch=20)
plot(infmed$infmat[,3],ylab="DFBeta(2)", pch=20)

# DFFITS, Distancia de Cook
par(mfrow=c(1,1),cex=1)
plot(infmed$infmat[,4], ylab="DFFits", pch=20)
plot(infmed$infmat[,5], ylab="CovRatio", pch=20)
plot(infmed$infmat[,6], ylab="Dist de Cook", pch=20)
plot(infmed$infmat[,7], ylab="hii", pch=20)


### Estudo do efeito das observa??es influentes no ajuste.
dadossem9=dados[-9,]
dadossem22=dados[-22,]
dadossem9e22=dados[-c(9,22),]

# Sem a observa??o 9:
ajuste2=lm(y~.,data=dadossem9)
summary(ajuste2)
anova(ajuste2,lm(y~1))
anova(ajuste2)

# Sem a observa??o 22:
ajuste3=lm(y~.,data=dadossem22)
summary(ajuste3)
anova(ajuste3)

# Sem as observa??es 9 e 22:
ajuste4=lm(y~.,data=dadossem9e22)
summary(ajuste4)
anova(ajuste4)

